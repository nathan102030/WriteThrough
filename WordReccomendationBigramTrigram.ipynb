{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Code snippet for trigram model tested in full pipeline."
      ],
      "metadata": {
        "id": "f2OiepjVFsn0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTrbFg0vFbUw"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "from nltk.corpus import reuters\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from collections import Counter\n",
        "import random\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('reuters')\n",
        "\n",
        "reuters_text = ' '.join(reuters.words())\n",
        "reuters_sents = [word_tokenize(sent) for sent in sent_tokenize(reuters_text)]\n",
        "\n",
        "tokens = [word.lower() for sentence in reuters_sents for word in sentence]\n",
        "bigrams = list(ngrams(tokens, 2))  # Bigrams (n=2)\n",
        "trigrams = list(ngrams(tokens, 3))  # Trigrams (n=3)\n",
        "\n",
        "bigram_freq = Counter(bigrams)\n",
        "trigram_freq = Counter(trigrams)\n",
        "\n",
        "def predict_next_word(start_sentence):\n",
        "    words = word_tokenize(start_sentence)\n",
        "    if len(words) < 2:\n",
        "        return predict_using_bigrams(start_sentence)\n",
        "\n",
        "    last_bigram = tuple(words[-2:])\n",
        "    trigram_candidates = {trigram[2]: freq for trigram, freq in trigram_freq.items() if trigram[:2] == last_bigram}\n",
        "\n",
        "    if trigram_candidates:\n",
        "        return max(trigram_candidates, key=trigram_candidates.get)\n",
        "    return predict_using_bigrams(start_sentence)\n",
        "\n",
        "def predict_using_bigrams(start_sentence):\n",
        "    words = word_tokenize(start_sentence)\n",
        "    if not words:\n",
        "        return None\n",
        "\n",
        "    last_word = words[-1].lower()\n",
        "    bigram_candidates = {bigram[1]: freq for bigram, freq in bigram_freq.items() if bigram[0] == last_word}\n",
        "\n",
        "    if bigram_candidates:\n",
        "        return max(bigram_candidates, key=bigram_candidates.get)\n",
        "    return None\n",
        "\n",
        "random.seed(42)\n",
        "test_data = random.sample(reuters_sents, 1000)\n",
        "\n",
        "def evaluate_accuracy(test_data):\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    for sentence in test_data:\n",
        "        if len(sentence) < 3:\n",
        "            continue\n",
        "\n",
        "        input_sentence = ' '.join(sentence[:-1])\n",
        "        actual_next_word = sentence[-1].lower()  # convert to lowercase\n",
        "\n",
        "        predicted_next_word = predict_next_word(input_sentence)\n",
        "\n",
        "        if predicted_next_word == actual_next_word:\n",
        "            correct_predictions += 1\n",
        "        total_predictions += 1\n",
        "\n",
        "    if total_predictions == 0:\n",
        "        return 0.0\n",
        "\n",
        "    accuracy = correct_predictions / total_predictions\n",
        "    return accuracy\n",
        "\n",
        "#start_sentence = \"The dictionary is filled with\"\n",
        "generated_text\n",
        "predicted_word = predict_next_word(generated_text)\n",
        "print(f\"Predicted next word for '{generated_text}': words\")\n",
        "\n",
        "accuracy = evaluate_accuracy(test_data)\n",
        "print(f\"Accuracy on 1000 test sentences from Reuters: {accuracy:.4f}\")"
      ]
    }
  ]
}